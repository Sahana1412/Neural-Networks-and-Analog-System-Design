{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hCKaS1GzCrO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import psutil\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# File paths\n",
        "image_dir = r\"C:\\Users\\mohan\\OneDrive\\Desktop\\First_year_assignments\\electrical\\Images\"\n",
        "labels_path = r\"C:\\Users\\mohan\\OneDrive\\Desktop\\First_year_assignments\\electrical\\captions.txt\"\n",
        "\n",
        "# Create a directory to save models and weights\n",
        "model_dir = \"models\"\n",
        "os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "# Load captions from TXT file\n",
        "def load_captions(file_path):\n",
        "    captions = []\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split(\",\", 1)\n",
        "            if len(parts) == 2:\n",
        "                image_name, caption = parts\n",
        "                captions.append((image_name.strip(), caption.strip()))\n",
        "    return pd.DataFrame(captions, columns=[\"image\", \"caption\"])\n",
        "\n",
        "labels_df = load_captions(labels_path)\n",
        "\n",
        "# Encode captions as numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels_df[\"label\"] = label_encoder.fit_transform(labels_df[\"caption\"])\n",
        "\n",
        "# Image preprocessing\n",
        "img_size = (128, 128)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Custom Dataset class\n",
        "class ImageCaptionDataset(Dataset):\n",
        "    def _init_(self, dataframe, img_dir, transform=None):\n",
        "        super()._init_()\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def _len_(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def _getitem_(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        label = self.dataframe.iloc[idx, 2]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# CNN Model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def _init_(self, num_classes):\n",
        "        super(SimpleCNN, self)._init_()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)  # Corrected this line\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "if _name_ == '_main_':\n",
        "    # Utilize maximum RAM and CPU\n",
        "    num_workers = psutil.cpu_count(logical=True)\n",
        "    batch_size = 32\n",
        "\n",
        "    dataset = ImageCaptionDataset(labels_df, image_dir, transform=transform)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = SimpleCNN(num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "    # Enable optimized GPU computations\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Training\n",
        "    num_epochs = 100\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (images, labels) in enumerate(data_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "            print(f\"Batch [{i+1}/{len(data_loader)}], Loss: {loss.item():.4f}, RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "\n",
        "        epoch_loss = running_loss / len(data_loader)\n",
        "        epoch_accuracy = 100 * (correct / total)\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%, RAM Usage: {psutil.virtual_memory().percent}%\")\n",
        "\n",
        "        # Save model checkpoint after every epoch\n",
        "        torch.save(model.state_dict(), os.path.join(model_dir, f\"model_epoch_{epoch+1}.pth\"))\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(model_dir, \"final_model.pth\")\n",
        "    torch.save(model.state_dict(), final_model_path)\n",
        "    print(f\"Final model saved at: {final_model_path}\")\n",
        "\n",
        "    # Save only the weights separately\n",
        "    weights_path = os.path.join(model_dir, \"model_weights.pth\")\n",
        "    torch.save(model.state_dict(), weights_path)\n",
        "    print(f\"Weights saved at: {weights_path}\")\n",
        "\n",
        "    # Plot learning curve\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(range(1, num_epochs+1), train_losses, label=\"Loss\", marker=\"o\", linestyle=\"-\")\n",
        "    plt.plot(range(1, num_epochs+1), train_accuracies, label=\"Accuracy\", marker=\"s\", linestyle=\"--\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.title(\"Training Loss & Accuracy Curve\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.savefig(os.path.join(model_dir, \"learning_curve.png\"))\n",
        "    plt.show()"
      ]
    }
  ]
}